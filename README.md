# RockPaperScissors_classifier

# Classifying rock paper scissors images with pytorch

The dataset contains images of hand gestures from the Rock-Paper-Scissors game.
The dataset was split to 1458 training examples and 730 test examples.
My model's test set accuracy is 99.17%.

The data was downloaded from kaggle (https://www.kaggle.com/drgfreeman/rockpaperscissors)

I used Transfer Learning (MobileNet) to train for my model.

![0P6uxM8Vr1DwySHe](https://user-images.githubusercontent.com/64536392/104521261-34777000-5605-11eb-953f-07a0d28418ef.png)
![2PAcPusQ59xIMfiw](https://user-images.githubusercontent.com/64536392/104521341-6557a500-5605-11eb-9005-87c05b287827.png)
![3dI7E5pwR07mvKvF](https://user-images.githubusercontent.com/64536392/104521398-7c969280-5605-11eb-8ce0-78776eb0cdc6.png)

Labeled as:
Paper = 0
Rock = 1
Scissors = 2
